# -*- coding: utf-8 -*-
"""ML_SSRF_Remediation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjvYhvgZdNHWmUn9OiOtyCAp7HQ4hybY

## Data Gathering Process - Using CVE API from NVD to Collect and Classify SSRF Vulnerability Data
"""

import requests
import json
import pandas as pd
import re

# CVE API URL for SSRF vulnerabilities
cve_api_url = "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=SSRF&resultsPerPage=2000"

# Send GET request to API
response = requests.get(cve_api_url)
if response.status_code == 200:
    data = response.json()
else:
    print(f"Error fetching data (Status Code: {response.status_code})")
    exit()

# Define a function to classify SSRF attack types from the description
def classify_attack(description):
    """Classifies SSRF attack types based on keywords and patterns in the description."""
    # Internal SSRF (Targeting internal systems like metadata services, localhost, or private IPs)
    if re.search(r'localhost|127\.0\.0\.1|169\.254|metadata|internal', description, re.IGNORECASE):
        return "Internal SSRF"
    # Protocol Abuse SSRF (Using gopher, dict, ftp, or other non-HTTP protocols)
    elif re.search(r'gopher://|file://|dict://|ftp://|http://localhost', description, re.IGNORECASE):
        return "Protocol Abuse SSRF"
    # DNS Rebinding SSRF (Abusing DNS resolution techniques)
    elif re.search(r'DNS|rebinding|resolve|hostname', description, re.IGNORECASE):
        return "DNS Rebinding SSRF"
    # Blind SSRF (No immediate feedback, often detected via external services)
    elif re.search(r'blind|out-of-band|OOB', description, re.IGNORECASE):
        return "Blind SSRF"
    # Cloud-Based SSRF (Targeting AWS, GCP, Azure, cloud storage, or metadata APIs)
    elif re.search(r'cloud|AWS|GCP|Azure|storage|bucket|cloud metadata', description, re.IGNORECASE):
        return "Cloud-Based SSRF"
    # Default: External SSRF (If none of the above match)
    else:
        return "External SSRF"

# Define a function to map CWE IDs to mitigation strategies
def map_mitigation(cwe_id):
    """Maps CWE IDs to security best practices for mitigation."""

    mitigation_dict = {
        "CWE-918": "Restrict internal network access, validate user input, use allowlists for URLs",
        "CWE-200": "Prevent sensitive data exposure using strict access control policies",
        "CWE-352": "Implement CSRF protection, enforce SameSite cookies, and use CSRF tokens",
        "CWE-400": "Use rate-limiting, request validation, and avoid unnecessary redirects",
        "CWE-601": "Prevent open redirects to untrusted domains, implement URL allowlists",
        "CWE-829": "Limit SSRF exposure by restricting external calls, use network segmentation",
        "CWE-94": "Sanitize input to prevent code injection through SSRF payloads",
        "CWE-287": "Ensure proper authentication mechanisms to block unauthorized requests",
        "CWE-610": "Use request signing to verify authenticity before processing external URLs",
        "CWE-441": "Restrict access to internal services from SSRF-exposed endpoints",
        "CWE-77": "Escape and validate input to prevent command injection via SSRF",
        "CWE-116": "Ensure error messages do not leak internal information",
        "CWE-185": "Sanitize and validate paths to prevent path traversal via SSRF",
        "CWE-611": "Disable XML external entity (XXE) processing to prevent SSRF exploitation",
        "CWE-113": "Prevent HTTP response splitting by sanitizing headers",
        "CWE-115": "Ensure proper encoding and decoding of transmitted data",
        "CWE-125": "Prevent out-of-bounds read attacks in memory manipulation",
        "CWE-1286": "Ensure proper authorization and access control for user actions",
        "CWE-20": "Implement strict input validation to prevent unexpected behavior",
        "CWE-201": "Limit the exposure of sensitive information in error messages",
        "CWE-22": "Prevent path traversal by validating and sanitizing input paths",
        "CWE-264": "Implement least privilege access control for all network services",
        "CWE-269": "Ensure proper role-based authentication and authorization",
        "CWE-288": "Require multi-factor authentication for sensitive resources",
        "CWE-330": "Use secure cryptographic randomness to prevent predictable exploits",
        "CWE-367": "Enforce race condition protections to prevent exploitation",
        "CWE-425": "Prevent unauthorized access to restricted URLs",
        "CWE-434": "Restrict file uploads to only expected content types",
        "CWE-502": "Sanitize and validate serialized data to prevent deserialization attacks",
        "CWE-691": "Ensure security mechanisms cannot be bypassed easily",
        "CWE-704": "Use strong type checking to prevent unexpected type manipulation",
        "CWE-74": "Sanitize user input to prevent injection attacks",
        "CWE-79": "Implement strict cross-site scripting (XSS) prevention mechanisms",
        "CWE-807": "Verify authenticity of received data before processing",
        "CWE-835": "Prevent infinite loops and excessive resource consumption",
        "CWE-862": "Enforce proper access control and authentication",
        "CWE-91": "Ensure secure data parsing to prevent code injection"
    }

    return mitigation_dict.get(cwe_id, "General SSRF Mitigation: Validate and sanitize all URLs, restrict network access, and enforce security controls.")

# Extract relevant features for ML model training
cve_records = []
for record in data.get("vulnerabilities", []):
    cve = record.get("cve", {})

    # Extract key details with default values if missing
    cve_id = cve.get("id", "N/A")
    description = cve.get("descriptions", [{}])[0].get("value", "No Description")
    severity = cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("baseSeverity", "N/A")
    attack_complexity = cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("attackComplexity", "N/A")
    attack_vector = cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("vectorString", "N/A")
    cwe_id = cve.get("weaknesses", [{}])[0].get("description", [{}])[0].get("value", "N/A")

    # Extract References (URLs)
    references = [ref.get("url", "No Reference") for ref in cve.get("references", [])]

    # Classify Attack Type
    attack_type = classify_attack(description)

    # Map CWE ID to Mitigation Strategy
    mitigation = map_mitigation(cwe_id)

    # Store extracted data
    cve_records.append({
        "CVE ID": cve_id,
        "Description": description,
        "Severity": severity,
        "Attack Complexity": attack_complexity,
        "Attack Vector": attack_vector,
        "CWE ID": cwe_id,
        "References": ", ".join(references),  # Convert list to string
        "Attack Type": attack_type,
        "Mitigation Strategy": mitigation
    })

# Convert to Pandas DataFrame
df = pd.DataFrame(cve_records)

# Save as CSV for ML training
df.to_csv("ssrf_cve_dataset.csv", index=False)

print("Data successfully fetched and saved as ssrf_cve_dataset.csv for ML model training!")

"""## Load the necessary libraries for data pre-processing, visualisation and training the ML algorithms models."""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

#Load the SSRF Vulnerabilities dataset and convert to Pandas DataFrame for data analysis
df = pd.read_csv('ssrf_cve_dataset.csv')

#Preview the dataframe first few rows
df.head()

# Count how many descriptions defaulted to 'External SSRF'
default_count = df[df["Attack Type"] == "External SSRF"].shape[0]
print(f"Number of CVEs defaulted to 'External SSRF': {default_count}")

# Percentage of total
default_percentage = (default_count / len(df)) * 100
print(f"Percentage of total: {default_percentage:.2f}%")

import random

# Get 10 random samples
sampled_rows = df.sample(50)

# Print CVE ID, Description, and Attack Type
for index, row in sampled_rows.iterrows():
    print(f"CVE ID: {row['CVE ID']}")
    print(f"Description: {row['Description']}")
    print(f"Mapped Attack Type: {row['Attack Type']}")
    print("-" * 80)

print(df['Attack Type'].value_counts())  # Check distribution of attack types
print(df['Mitigation Strategy'].value_counts())  # Check mitigation class balance

# Check if rows with missing details/NaN or NULL values exists
df.isnull().sum()

#Displays info about dataframe such as null values, columns and entries.
df.info()

"""### Total No. of Rows before removing NaN Values: 487
### After removing NaN values: 358
"""

# Remove these null entries in columns from dataset
df = df.dropna(subset=['Severity', 'Attack Complexity', 'Attack Vector', 'CWE ID'])

# Verify that these null entries are removed from columns data
print(df.isnull().sum())

# New number of rows after cleaning up
print("New no. of rows: " + str(len(df)))

#Further pre-processing from feature selection by keeping only relevant columns for further analysis
relevant_columns = ['CVE ID', 'CWE ID', 'Attack Type', 'Mitigation Strategy']
df = df[relevant_columns]

#Check for any duplicate rows to ensure accurate analysis
print("Duplicate rows count:", df.duplicated().sum())

#Preview the first few rows of dataset after removal of NaN values
df.head()

"""## Exploratory Data Analysis"""

# Distribution of Attack Types with total counts
plt.figure(figsize=(8, 5))
sns.countplot(x='Attack Type', data=df, palette="viridis")
plt.title("Distribution of Attack Types")
plt.xlabel("Attack Type")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()

## Distribution Analysis (CWE IDs Across Attack Types) with total counts
plt.figure(figsize=(12, 6))
sns.countplot(x="CWE ID", hue="Attack Type", data=df, palette="Set2")
plt.xticks(rotation=45)
plt.title("Distribution of CWE IDs Across Attack Types")
plt.xlabel("CWE ID")
plt.ylabel("Count")
plt.legend(title="Attack Type")
plt.show()

# Encoding categorical variables into numerical values for model training
label_encoders = {}
for col in ['Attack Type', 'Mitigation Strategy']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Store encoders for future reference

# Print label mapping for each encoded column
for col in ['Attack Type', 'Mitigation Strategy']:
    print(f"\nLabel Encoding Mapping for {col}:")
    for class_index, class_label in enumerate(label_encoders[col].classes_):
        print(f" {class_label} --> {class_index}")

#Confirm the label encoding for the following columns are successsfully applied
df.head()

# Remove "CWE-" prefix and convert to numeric for model training
df['CWE ID'] = df['CWE ID'].str.replace("CWE-", "").astype(int)  # Convert "CWE-918" → 918

# Verify the DataFrame
df.head()

# Save preprocessed dataset
df.to_csv("preprocessed_ssrf_dataset.csv", index=False)
print("Data preprocessing completed. Preprocessed dataset saved as 'preprocessed_ssrf_dataset.csv'")

"""## Train the ML Model Algorithms - trains and evaluates classification models to predict mitigation strategies for SSRF (Server-Side Request Forgery) attacks based on CWE ID and Attack Type"""

# Define independent variables (X) and dependent variable (y)
X = df[['CWE ID', 'Attack Type']]  # Features
y = df['Mitigation Strategy']  # Target (Labels)

# Split dataset into training (80%) and testing (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Function to train & evaluate models
def train_and_evaluate(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    # Evaluation Metrics
    # Compute Accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Compute Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)

    # Compute Classification Report
    report = classification_report(y_test, y_pred, zero_division=1)

    # Print Model Performance
    print(f"\n{name} Model Performance:")
    print(f"Accuracy: {accuracy:.4f}")
    print("\nClassification Report:\n", report)

    # Plot Confusion Matrix
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=set(y_test), yticklabels=set(y_test))
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title(f"Confusion Matrix for {name}")
    plt.show()

    return model

# Train & Evaluate Models
dt_model = train_and_evaluate(DecisionTreeClassifier(random_state=42), "Decision Tree")
xgb_model = train_and_evaluate(XGBClassifier(eval_metric="mlogloss", random_state=42), "XGBoost")
rf_model = train_and_evaluate(RandomForestClassifier(n_estimators=100, random_state=42), "Random Forest")

# Testing of best performance decisioin tree model to predict correct mitigation strategy/recommendations based on features trained

# CWE ID to CWE Name Mapping
cwe_name_mapping = {
    918: "Server-Side Request Forgery (SSRF)",
    200: "Exposure of Sensitive Information to an Unauthorized Actor",
    352: "Cross-Site Request Forgery (CSRF)",
    400: "Uncontrolled Resource Consumption",
    601: "URL Redirection to Untrusted Site ('Open Redirect')",
    829: "Inclusion of Functionality from Untrusted Control Sphere",
    94: "Code Injection",
    287: "Improper Authentication",
    610: "Externally Controlled Reference to a Resource in Another Sphere",
    441: "Unintended Proxy or Intermediary ('Confused Deputy')",
    77: "Command Injection",
    116: "Improper Encoding or Escaping of Output",
    185: "Incorrect Authorization",
    611: "Improper Restriction of XML External Entity Reference (XXE)",
    113: "Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')",
    115: "Improper Neutralization of Input During Writing of Files",
    125: "Out-of-bounds Read",
    1286: "Improper Access Control",
    20: "Improper Input Validation",
    201: "Information Exposure Through Sent Data",
    22: "Path Traversal",
    264: "Permissions, Privileges, and Access Control",
    269: "Improper Privilege Management",
    288: "Authentication Bypass Issues",
    330: "Use of Insufficiently Random Values",
    367: "Time-of-check Time-of-use (TOCTOU) Race Condition",
    425: "Direct Request ('Forced Browsing')",
    434: "Unrestricted File Upload",
    502: "Deserialization of Untrusted Data",
    691: "Insufficient Control Flow Management",
    704: "Incorrect Type Conversion or Cast",
    74: "Improper Neutralization of Special Elements in Output Used by a Downstream Component ('Injection')",
    79: "Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
    807: "Reliance on Untrusted Inputs in a Security Decision",
    835: "Loop with Unreachable Exit Condition ('Infinite Loop')",
    862: "Missing Authorization",
    91: "XML Injection (aka Blind XPath Injection)"
}

# Attack Type Mapping Dictionary
attack_type_mapping = {
    0: "Blind SSRF",
    1: "Cloud-Based SSRF",
    2: "DNS Rebinding SSRF",
    3: "External SSRF",
    4: "Internal SSRF",
    5: "Protocol Abuse SSRF"
}

# Define function for mitigation prediction based on CWE ID, Attack Type input features
def predict_mitigation(model, cwe_id, attack_type):
    # Convert input to DataFrame to avoid feature name warning
    input_data = pd.DataFrame([[cwe_id, attack_type]], columns=['CWE ID', 'Attack Type'])

    # Predict mitigation strategy
    prediction = model.predict(input_data)[0]

    # Convert back to label
    mitigation_strategy = label_encoders['Mitigation Strategy'].inverse_transform([prediction])[0]

    # Get CWE Name and Attack Type Name
    cwe_name = cwe_name_mapping.get(cwe_id, f"CWE {cwe_id}")
    attack_type_name = attack_type_mapping.get(attack_type, f"Attack Type {attack_type}")

    return cwe_name, attack_type_name, mitigation_strategy

# Testing of the mapping to mitigation strategy/recommendation prediction from CWE ID of vulnerability and attack type for reference using decision tree model
cwe_example = 918  # Example input of CWE ID
attack_type_example = 2 # Example input of attack type

# Predict mitigation strategy
cwe_name, attack_type_name, predicted_remediation = predict_mitigation(dt_model, cwe_example, attack_type_example)

# Print the formatted result
print(f"\nPredicted Mitigation Strategy for CWE {cwe_example} ({cwe_name}) & Attack Type of vulnerability ({attack_type_name}): {predicted_remediation}")

"""## Deploy the best performance Decision Tree model using Pickle for further use in deployed environment"""

import pickle

# Save the trained Decision Tree model to deploy the model for further use
with open("decision_tree_model.pkl", "wb") as model_file:
    pickle.dump(dt_model, model_file)

print("Decision Tree model saved successfully!")

# Load the trained Decision Tree model to use in deployed environment
with open("decision_tree_model.pkl", "rb") as model_file:
    loaded_model = pickle.load(model_file)

print("Decision Tree model loaded successfully!")

# Make predictions on mitigation strategies using the best performance decision tree model once loaded

''' Map CWE ID to its corresponding name using a predefined dictionary (cwe_names),
Ensure attack type name is used instead of the encoded number used for training.
'''
cwe_names = {
    918: "Server-Side Request Forgery (SSRF)",
    200: "Exposure of Sensitive Information to an Unauthorized Actor",
    352: "Cross-Site Request Forgery (CSRF)",
    400: "Uncontrolled Resource Consumption",
    601: "URL Redirection to Untrusted Site ('Open Redirect')",
    829: "Inclusion of Functionality from Untrusted Control Sphere",
    94: "Code Injection",
    287: "Improper Authentication",
    610: "Externally Controlled Reference to a Resource in Another Sphere",
    441: "Unintended Proxy or Intermediary ('Confused Deputy')",
    77: "Command Injection",
    116: "Improper Encoding or Escaping of Output",
    185: "Incorrect Authorization",
    611: "Improper Restriction of XML External Entity Reference (XXE)",
    113: "Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')",
    115: "Improper Neutralization of Input During Writing of Files",
    125: "Out-of-bounds Read",
    1286: "Improper Access Control",
    20: "Improper Input Validation",
    201: "Information Exposure Through Sent Data",
    22: "Path Traversal",
    264: "Permissions, Privileges, and Access Control",
    269: "Improper Privilege Management",
    288: "Authentication Bypass Issues",
    330: "Use of Insufficiently Random Values",
    367: "Time-of-check Time-of-use (TOCTOU) Race Condition",
    425: "Direct Request ('Forced Browsing')",
    434: "Unrestricted File Upload",
    502: "Deserialization of Untrusted Data",
    691: "Insufficient Control Flow Management",
    704: "Incorrect Type Conversion or Cast",
    74: "Improper Neutralization of Special Elements in Output Used by a Downstream Component ('Injection')",
    79: "Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
    807: "Reliance on Untrusted Inputs in a Security Decision",
    835: "Loop with Unreachable Exit Condition ('Infinite Loop')",
    862: "Missing Authorization",
    91: "XML Injection (aka Blind XPath Injection)"
}

# Mapping to mitigation strategy/recommendation prediction from CWE ID of vulnerability and attack type using decision tree model
cwe_example = 918  # Example CWE ID
attack_type_example = 3  # Example Attack Type for reference

# Convert input to DataFrame
input_data = pd.DataFrame([[cwe_example, attack_type_example]], columns=['CWE ID', 'Attack Type'])

# Predict the mitigation strategy
prediction = loaded_model.predict(input_data)[0]

# Convert back to label using stored label encoder
predicted_mitigation = label_encoders["Mitigation Strategy"].inverse_transform([prediction])[0]

# Get CWE Name (Ensure default if not found)
cwe_name = cwe_names.get(cwe_example, f"{cwe_example}")

# Get Attack Type Name using the Label Encoder
attack_type_name = label_encoders["Attack Type"].inverse_transform([attack_type_example])[0]

# Print the formatted output
print(f"Predicted Mitigation Strategy for CWE {cwe_example} ({cwe_name}) & Attack Type of vulnerability ({attack_type_name}): {predicted_mitigation}")